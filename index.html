<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>Privacy Preserving Machine Learning - PriML and PPML Joint Edition (Neurips 2020 Workshop)</title>
    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- MathJax -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script src="js/mathjax/es5/tex-mml-chtml.js"></script>
</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
    <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">
                    <span class="light">PriML/PPML'20</span>
                </a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#about">Scope</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">CFP &amp; Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#speakers">Invited Speakers</a>
                    </li>
                    <!-- <li> -->
                    <!--     <a class="page-scroll" href="#schedule">Schedule</a> -->
                    <!-- </li> -->
                    <!-- <li> -->
                    <!--     <a class="page-scroll" href="#papers">Accepted Papers</a> -->
                    <!-- </li> -->
                    <!--<li>
                        <a class="page-scroll" href="#grants">Travel Grants</a>
                    </li>-->
                    <li>
                        <a class="page-scroll" href="#organizers">Organizers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#previous">Previous Editions</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <!-- Intro Header -->
    <header class="intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <h1 class="brand-heading">Privacy Preserving Machine Learning - PriML and PPML Joint Edition</h1>
                        <p class="intro-text">Neurips 2020 Workshop
                            <br />Virtual workshop, December
                        </p>
                        <!--<p class="location-text">
                            Palais des Congrès de Montréal
                            <br /> Room: 512CDGH
                        </p>-->
                    </div>
                </div>
            </div>
        </div>
    </header>
    <!-- About Section -->
    <section id="about" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              <h2>Scope</h2>
              <p>This one day workshop focuses on privacy preserving techniques for machine learning and disclosure in large scale data analysis, both in the distributed and centralized settings, and on scenarios that highlight the importance and need for these techniques (e.g., via privacy attacks). There is growing interest from the Machine Learning (ML) community in leveraging cryptographic techniques such as Multi-Party Computation (MPC) and Homomorphic Encryption (HE) for privacy preserving training and inference, as well as Differential Privacy (DP) for disclosure. Simultaneously, the systems security and cryptography community has proposed various secure frameworks for ML. We encourage both theory and application-oriented submissions exploring a range of approaches listed below. Additionally, given the tension between the adoption of machine learning technologies and ethical, technical and regulatory issues about privacy, as highlighted during the Covid-19 pandemic, we invite submissions for the special track on this topic.</p>
   <ul class="list-group">
     <li class="list-group-item speaker">Special track: privacy of ML and data analytics in health care (e.g., secure contact tracing)</li>
     <li class="list-group-item speaker">Differential privacy and other statistical notions of privacy: theory, applications, and implementations</li>
     <li class="list-group-item speaker">Secure multi-party computation techniques for ML</li>
     <li class="list-group-item speaker">Learning on encrypted data</li>
     <li class="list-group-item speaker">Hardware-based approaches to privacy-preserving ML</li>
     <li class="list-group-item speaker">Trade-offs between privacy and utility</li>
     <li class="list-group-item speaker">Privacy attacks</li>
     <li class="list-group-item speaker">Federated and decentralized privacy-preserving algorithms</li>
     <li class="list-group-item speaker">Programming languages for privacy-preserving data analysis</li>
     <li class="list-group-item speaker">Empirical and theoretical comparisons between different notions of privacy</li>
     <li class="list-group-item speaker">Policy-making aspects of data privacy</li>
     <li class="list-group-item speaker">Privacy in autonomous systems</li>
     <li class="list-group-item speaker">Online social networks privacy</li>
     <li class="list-group-item speaker">Interplay between privacy and adversarial robustness in machine learning</li>
     <li class="list-group-item speaker">Relations between privacy, fairness and transparency</li>
     <li class="list-group-item speaker">Applications of privacy-preserving ML</li>
   </ul>
   <!-- <p>We think it will be very valuable to have a forum to unify different perspectives and start a -->
   <!--   discussion about the relative merits of each approach. The workshop will also serve as a venue for -->
   <!--   networking people from different communities interested in this problem, and hopefully foster -->
   <!--   fruitful long-term collaboration.</p> -->
            </div>
        </div>
    </section>
    <!-- CFP & Dates Section -->
    <section id="dates" class="container content-section text-center">
      <div class="row">
        <div class="col-lg-8 col-lg-offset-2">
          <h2>Call For Papers &amp; Important Dates</h2>
          <a href="cfp-ppml20.txt" class="btn btn-default btn-lg">Download Full CFP</a>
          <br />
          <br />
          <br />
          <p>
                    <b>Submission deadline</b>: Oct 02, 2020
                    <br /><b>Notification of acceptance</b>: Oct 23, 2020
                    <!-- <br /><b>CCS early <a -->
                    <!--                      href="https://www.sigsac.org/ccs/CCS2019/index.php/attending/registration/">registration</a> -->
                    <!--   deadline</b>: October 1, 2019 (11:59PM BST) -->
                    <!-- <br /><b>Workshop</b>: November 15, 2019 -->
          </p>
          <h3>Submission Instructions</h3>
          <p>
            Submissions in the form of extended abstracts must be at most 4 pages long (not including references; additional supplementary material may be submitted but may be ignored by reviewers), non-anonymized and adhere to the NeurIPS format. We do accept submissions of work recently published or currently under review. The workshop will not have formal proceedings, but authors of accepted abstracts can choose to have a link to arxiv or a pdf published on the workshop webpage. Submissions for the special track should clearly state “Special track” in their title.</p>
          </p>
          <a href=" https://easychair.org/my/conference?conf=ppml2020" class="btn btn-default btn-lg">Submit Your  Abstract</a>
        </div>
      </div>
      <!-- <br /> -->
      <!-- <br /> -->
      <!-- <br /> -->
      <!-- <div class="row"> -->
      <!--   <div class="col-lg-8 col-lg-offset-2"> -->
      <!--     <h3>Poster Instructions</h3> -->
      <!--     <p> -->
      <!--       All accepted papers have a slot at the poster session. Please print your poster on size up to A0 -->
      <!--       (841 × 1189 mm) and bring it to the conference. -->
      <!--     </p> -->
      <!--   </div> -->
      <!-- </div> -->
    </section>
    <!-- Call for travel grants -->
    <!-- <section id="grants" class="container content-section text-center"> -->
    <!--     <div class="row"> -->
    <!--         <div class="col-lg-8 col-lg-offset-2"> -->
    <!--             <h2>Travel Grants</h2> -->
    <!--             <p> -->
    <!--                 Thanks to our generous sponsors, we are able to provide a limited number of travel grants of up to -->
    <!--                 $800 to help partially cover the expenses of PPML attendees who have not received other travel -->
    <!--                 support from CCS this year. -->
    <!--                 To apply, please send an email to <a -->
    <!--                     href="mailto:ppml19@easychair.org?Subject=PPML19%20Travel%20Grant%20Application">ppml19@easychair.org</a> -->
    <!--                 with the subject “PPML19 Travel Grant Application” including a half-page statement of purpose and a -->
    <!--                 summary of anticipated travel expenses. If you are an undergraduate or graduate student, we ask for -->
    <!--                 a half-page recommendation letter supporting your application to be sent by the deadline to the same -->
    <!--                 email address. The deadline for applications is <b>Sep 23, 2019 (11:59pm AoE)</b>. The notifications -->
    <!--                 will be sent by <b>Sep 30</b>. Please feel free to send us an email if you have any questions. -->
    <!--             </p> -->
    <!--         </div> -->
    <!--     </div> -->
    <!-- </section> -->
    <!-- Speakers Section -->
    <section id="speakers" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Invited Speakers</h2>
                <ul class="list-group">
                  <li class="list-group-item speaker"><a href="https://people.epfl.ch/carmela.troncoso">Carmela Troncoso</a> (EPFL)</li>
                  <li class="list-group-item speaker"><a href="https://www.cs.huji.ac.il/~katrina/">Katrina Ligett</a> (Hebrew University)</li>
                  <li class="list-group-item speaker"><a href="https://www.comp.nus.edu.sg/~reza/">Reza Shokri</a> (National University of Singapore)</li>
                </ul>
            </div>
        </div>
    </section>
    <!-- Schedule Section -->
    <!-- <section id="schedule" class="container content-section text-center"> -->
    <!--     <div class="row"> -->
    <!--         <div class="col-sm-8 col-sm-offset-2"> -->
    <!--             <h2>Schedule</h2> -->
    <!--             <table class="table schedule"> -->
    <!--                 <tbody> -->
    <!--                     <\!-- Basic slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">8:50</td> -->
    <!--                         <td class="slot">Welcome</td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Invited slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">9:00</td> -->
    <!--                         <td class="slot talk"> -->
    <!--                             Invited talk: -->
    <!--                             <a href="#tabs1" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Kobbi Nissim -->
    <!--                                 &mdash; -->
    <!--                                 Legal Theorems of Privacy -->
    <!--                             </a> -->
    <!--                         </td> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs1"> -->
    <!--                                 Significant gaps between legal and technical thinking around data privacy make it -->
    <!--                                 hard to exactly understand how legal standards apply to economic mechanisms that use -->
    <!--                                 personal information. Such mechanisms may apply technical solutions constructed -->
    <!--                                 under frameworks such as differential privacy and k-anonymity. However, there is a -->
    <!--                                 lot of uncertainty regarding how these mathematical concepts meet legal standards. -->
    <!--                                 As a result, arguments that mechanisms apply sufficient technical privacy measures -->
    <!--                                 for satisfying legal privacy often lack rigor, and their conclusions are uncertain. -->
    <!--                                 The uncertainty is exacerbated by a litany of successful privacy attacks on privacy -->
    <!--                                 measures thought to meet legal expectations but then shown to fall short of doing -->
    <!--                                 so. -->

    <!--                                 We examine strategies for introducing mathematical rigor into the analysis, so as to -->
    <!--                                 make formal claims and prove “legal theorems” that technical privacy measures meet -->
    <!--                                 legal expectations. For that, we explore some of the gaps between these two very -->
    <!--                                 different approaches, and present initial strategies towards bridging these gaps -->
    <!--                                 considering examples from US and EU law. -->

    <!--                                 Based on joint works with Aaron Bembenek, Mark Bun, Aloni Cohen, Marco Gaboardi, Urs -->
    <!--                                 Gasser, David R. O’Brien, Thomas Steinke, Alexandra Wood, and Salil Vadhan. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Contributed slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">9:45</td> -->
    <!--                         <td class="slot talk"><a href="#tabs2" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Secure parallel computation on national scale volumes of data</a> -->
    <!--                             (contributed talk) -->
    <!--                             <br /> -->
    <!--                             <span style="font-weight: normal"> -->
    <!--                                 Sahar Mazloom, Le Phi Hung, Samuel Ranellucci and S. Dov Gordon -->
    <!--                             </span> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs2"> -->
    <!--                                 In this work, we revisit secure computation of graph parallel algorithms, -->
    <!--                                 simultaneously leveraging all three of the following advances: we assume four -->
    <!--                                 computation servers (with an honest majority, and one malicious corruption), allow -->
    <!--                                 differentially private leakage during computation, and, exploiting the parallelism -->
    <!--                                 that this affords, we construct an MPC protocol that can perform at national scales. -->
    <!--                                 Concretely, we compute histograms on 300 million inputs in 4.18 minutes, and we -->
    <!--                                 perform sparse matrix factorization, which is used in recommendation systems, on 20 -->
    <!--                                 million inputs in under 6 minutes. These problems have broad, real-world -->
    <!--                                 applications, and, at this scale, we could imagine supporting the CensusBureau, or a -->
    <!--                                 large company such as Amazon. For comparison, the largest experiments in GraphSC [6] -->
    <!--                                 and OblivGraph [18] had 1M inputs, and required 13 hours and 2 hours of runtime, -->
    <!--                                 respectively, while using 4 times the number of processors that we employ. -->
    <!--                                 End-to-end, our construction is 320X faster than OblivGraph. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Break slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">10:05</td> -->
    <!--                         <td class="break">Poster Session and Coffee Break</td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Invited slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">10:45</td> -->
    <!--                         <td class="slot talk"> -->
    <!--                             Invited talk: -->
    <!--                             <a href="#tabs3" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Rachel Cummings -->
    <!--                                 &mdash; -->
    <!--                                 Differential Privacy for Dynamic Databases -->
    <!--                             </a> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs3"> -->
    <!--                                 Privacy concerns are becoming a major obstacle to using data in the ways we want. -->
    <!--                                 How can data scientists make use of potentially sensitive data, while providing -->
    <!--                                 rigorous privacy guarantees to the individuals who provided data? Over the last -->
    <!--                                 decade, differential privacy has emerged as the de facto gold standard of privacy -->
    <!--                                 preserving data analysis. Differential privacy ensures that an algorithm does not -->
    <!--                                 overfit to the individuals in the database by guaranteeing that if any single entry -->
    <!--                                 in the database were to be changed, then the algorithm would still have -->
    <!--                                 approximately the same distribution over outputs.<br /> -->

    <!--                                 In this talk, we will focus on recent advances in differential privacy for dynamic -->
    <!--                                 databases, where the content of the database evolves over time as new data are -->
    <!--                                 acquired. First, we will see how to extend differentially private algorithms for -->
    <!--                                 static databases to the dynamic setting, with relatively small loss in the -->
    <!--                                 privacy-accuracy tradeoff. Next, we see algorithms for privately detecting changes -->
    <!--                                 in data composition. We will conclude with a discussion of open problems in this -->
    <!--                                 space, including the use of differential privacy for other types of data -->
    <!--                                 dynamism.<br /> -->

    <!--                                 (based on joint works with Sara Krehbiel, Kevin Lai, Yuliia Lut, Yajun Mei, Uthaipon -->
    <!--                                 (Tao) Tantipongpipat, Rui Tuo, and Wanrong Zhang.) -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Contributed slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">11:30</td> -->
    <!--                         <td class="slot talk"><a href="#tabs4" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Garbled Neural Networks are Practical -->
    <!--                             </a> -->
    <!--                             (contributed talk) -->
    <!--                             &nbsp;&nbsp; -->
    <!--                             <br /> -->
    <!--                             <span style="font-weight: normal"> -->
    <!--                                 Marshall Ball, Brent Carmer, Tal Malkin, Mike Rosulek and Nichole Schimanski -->
    <!--                             </span> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs4"> -->
    <!--                                 We show that garbled circuits offer a practical choice for secure evaluation of -->
    <!--                                 neural network classifiers, comparable with complex, specialized protocols using -->
    <!--                                 less robust assumptions, many rounds of interaction, and/or tailor-made neural -->
    <!--                                 networks. In particular, we develop a scheme for garbling ``off the shelf'' -->
    <!--                                 pre-trained neural networks, where the only model preprocessing required is a mild -->
    <!--                                 discretization step as opposed to requiring a specialized SFE-friendly model to be -->
    <!--                                 independently trained. Moreover, as our solution is a garbling scheme, it inherits a -->
    <!--                                 much more diverse range of applications than non-garbling-based solutions, perhaps -->
    <!--                                 most notably, efficient compilers for the malicious setting. At the protocol level, -->
    <!--                                 we start with the garbling scheme of Ball, Malkin, and Rosulek (ACM CCS 2016) for -->
    <!--                                 arithmetic circuits and introduce new optimizations for modern neural network -->
    <!--                                 activation functions. We develop fancygarbling, the first implementation of the -->
    <!--                                 BMR16 garbling scheme along with our new optimizations, as part of heavily optimized -->
    <!--                                 garbled-circuits tool that is driven by a TensorFlow classifier description. We -->
    <!--                                 evaluate our constructions on a wide range of neural networks. We find that our -->
    <!--                                 approach is up to 100x more efficient than straight-forward boolean garbling. It is -->
    <!--                                 also roughly 40% more efficient than DeepSecure (Rouhani et al., DAC 2018), a recent -->
    <!--                                 garbled-circuit-based approach for secure neural network evaluation, which -->
    <!--                                 incorporates significant optimization techniques for boolean circuits. Furthermore, -->
    <!--                                 our approach provides competitive performance tradeoffs (efficiency and latency vs. -->
    <!--                                 communication) also when compared with non-garbled-circuit approaches. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Contributed slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">11:50</td> -->
    <!--                         <td class="slot talk"><a href="#tabs5" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Learning Rate Adaptation for Federated and Differentially Private Learning -->
    <!--                             </a> -->
    <!--                             (contributed talk) -->
    <!--                             &nbsp;&nbsp; -->
    <!--                             <br /> -->
    <!--                             <span style="font-weight: normal"> -->
    <!--                                 Antti Koskela and Antti Honkela -->
    <!--                             </span> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs5"> -->
    <!--                                 We propose an algorithm for the adaptation of the learning rate for stochastic -->
    <!--                                 gradient descent (SGD) that avoids the need for validation set use. The idea for the -->
    <!--                                 adaptiveness comes from the technique of extrapolation: to get an estimate for the -->
    <!--                                 error against the gradient flow which underlies SGD, we compare the result obtained -->
    <!--                                 by one full step and two half-steps. The algorithm is applied in two separate -->
    <!--                                 frameworks: federated and differentially private learning. Using examples of deep -->
    <!--                                 neural networks we empirically show that the method works robustly in the case of -->
    <!--                                 federated learning unlike commonly used optimisation methods. We also show that the -->
    <!--                                 adaptive algorithm is competitive with state-of-the-art hyperparameter search -->
    <!--                                 methods and commonly used optimisation methods for differentially privately -->
    <!--                                 training. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Basic slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">12:10</td> -->
    <!--                         <td class="slot talk"> -->
    <!--                             <a href="#lightningtalks" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Lightning Talks -->
    <!--                             </a> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="lightningtalks"> -->
    <!--                                 1. Nitin Agrawal, Ali Shahin Shamsabadi, Matthew Kusner and Adrià Gascón. QUOTIENT: -->
    <!--                                 Secure Two-Party Neural Network Training and Prediction via Oblivious Transfer<br /> -->
    <!--                                 2. Yuantian Miao, Ben Zi Hao Zhao, Minhui Xue, Chen Chao, Lei Pan, Jun Zhang, Dali -->
    <!--                                 Kaafar and Yang Xiang. The Audio Auditor: Participant-Level Membership Inference in -->
    <!--                                 Internet of Things Voice Services<br /> -->
    <!--                                 3. Harsh Chaudhari, Ashish Choudhury, Arpita Patra and Ajith Suresh. ASTRA: High -->
    <!--                                 Throughput 3PC over Rings with Application to Secure Prediction<br /> -->
    <!--                                 4. Brendan Avent, Javier Gonzalez, Tom Diethe, Andrei Paleyes and Borja Balle. -->
    <!--                                 Automatic Discovery of Privacy-Utility Pareto Fronts<br /> -->
    <!--                                 5. Marco Romanelli, Konstantinos Chatzikokolakis and Catuscia Palamidessi. Optimal -->
    <!--                                 Obfuscation Mechanisms via Machine Learning and Applications to Location -->
    <!--                                 Privacy<br /> -->
    <!--                                 6. Niek J. Bouman and Niels de Vreede. A Practical Approach to the Secure -->
    <!--                                 Computation of the Moore-Penrose Pseudoinverse over the Rationals<br /> -->
    <!--                                 7. James Bell, Aurélien Bellet, Adria Gascon and Tejas Kulkarni. Private Protocols -->
    <!--                                 for -statistics in the Local Model and Beyond<br /> -->
    <!--                                 8. Mark Abspoel, Niek J. Bouman, Berry Schoenmakers and Niels de Vreede. Fast -->
    <!--                                 Secure Comparison for Medium-Sized Integers and Its Application in Binarized Neural -->
    <!--                                 Networks<br /> -->
    <!--                                 9. Devin Reich, Ariel Todoki, Rafael Dowsley, Martine De Cock and Anderson -->
    <!--                                 Nascimento. Secret Sharing based Private Text Classification<br /> -->
    <!--                                 10. Qingrong Chen, Chong Xiang, Minhui Xue, Bo Li, Nikita Borisov, Dali Kaafar and -->
    <!--                                 Haojin Zhu. Differentially Private Data Sharing: Sharing Models versus Sharing -->
    <!--                                 Data<br /> -->
    <!--                                 11. Antti Koskela, Joonas Jälkö and Antti Honkela. Computing Exact Guarantees for -->
    <!--                                 Differential Privacy<br /> -->
    <!--                                 12. Thijs Veugen, Bart Kamphorst, Marie Beth van Egmond and Natasja van de L'Isle. -->
    <!--                                 Privacy-Preserving Coupling of Vertically-Partitioned Databases and Subsequent -->
    <!--                                 Training with Gradient Descent<br /> -->
    <!--                                 13. Sebastian P. Bayerl, Ferdinand Brasser, Christoph Busch, Tommaso Frassetto, -->
    <!--                                 Patrick Jauernig, Jascha Kolberg, Andreas Nautsch, Korbinian Riedhammer, Ahmad-Reza -->
    <!--                                 Sadeghi, Thomas Schneider, Emmanuel Stapf, Amos Treiber and Christian Weinert. -->
    <!--                                 Privacy-Preserving Speech Processing via STPC and TEEs<br /> -->
    <!--                                 14. Ranya Aloufi, Hamed Haddadi and David Boyle. Emotionless: Privacy-Preserving -->
    <!--                                 Speech Analysis for Voice Assistants<br /> -->
    <!--                                 15. Lukas Burkhalter, Alexander Viand, Anwar Hithnawi and Hossein Shafagh. Robust -->
    <!--                                 Secure Aggregation for Privacy-Preserving Federated Learning with Adversaries<br /> -->
    <!--                                 16. Anders Dalskov, Daniel Escudero and Marcel Keller. Secure Evaluation of -->
    <!--                                 Quantized Neural Networks<br /> -->
    <!--                                 17. Mohammad Yaghini, Bogdan Kulynych and Carmela Troncoso. Disparate Vulnerability: -->
    <!--                                 on the Unfairness of Privacy Attacks Against Machine Learning<br /> -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Break slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">12:40</td> -->
    <!--                         <td class="break">Poster Session and Lunch Break</td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Invited slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">14:00</td> -->
    <!--                         <td class="slot talk"> -->
    <!--                             Invited talk: -->
    <!--                             <a href="#tabs6" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Vitaly Shmatikov -->
    <!--                                 &mdash; -->
    <!--                                 Unwanted Machine Learning -->
    <!--                             </a> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs6"> -->
    <!--                                 Modern machine learning models exhibit amazing accuracy on tasks from image -->
    <!--                                 classification to natural-language processing, but accuracy does not tell the entire -->
    <!--                                 story of what these models have learned. Does a model memorize and leak its training -->
    <!--                                 data? Does it “accidentally" learn privacy-violating tasks uncorrelated with its -->
    <!--                                 training objective? Can it hide a backdoor introduced by an adversary? All of these -->
    <!--                                 are examples of unwanted learning, which we need to understand and mitigate in order -->
    <!--                                 to solve security and privacy problems in today's AI. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Contributed slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">14:45</td> -->
    <!--                         <td class="slot talk"><a href="#tabs7" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 On Inferring Training Data Attributes in Machine Learning Models -->
    <!--                             </a> -->
    <!--                             (contributed talk) -->
    <!--                             &nbsp;&nbsp; -->
    <!--                             <br /> -->
    <!--                             <span style="font-weight: normal"> -->
    <!--                                 Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Raghav Bhaskar and Mohamed Ali Kaafar -->
    <!--                             </span> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs7"> -->
    <!--                                 A number of recent works have demonstrated that API access to machine learning -->
    <!--                                 models leaks information about the dataset records used to train the models. -->
    <!--                                 Further, the work of [9] shows that such membership inference attacks (MIAs) may be -->
    <!--                                 sufficient to construct a stronger breed of attribute inference attacks (AIAs), -->
    <!--                                 which given a partial view of a record can guess the missing attributes. In this -->
    <!--                                 work, we show (to the contrary) that MIA may not be sufficient to build a successful -->
    <!--                                 AIA. This is because the latter requires the ability to distinguish between similar -->
    <!--                                 records (differing only in a few attributes), and, as we demonstrate, the current -->
    <!--                                 breed of MIA are unsuccessful in distinguishing member records from similar -->
    <!--                                 non-member records. We thus propose a relaxed notion of AIA, whose goal is to only -->
    <!--                                 approximately guess the missing attributes and argue that such an attack is more -->
    <!--                                 likely to be successful, if MIA is to be used as a subroutine for inferring training -->
    <!--                                 record attributes. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Break slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">15:05</td> -->
    <!--                         <td class="break">Poster Session and Coffee Break</td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Invited slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">15:45</td> -->
    <!--                         <td class="slot talk"> -->
    <!--                             Invited talk: -->
    <!--                             <a href="#tabs8" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Kim Laine -->
    <!--                                 &mdash; -->
    <!--                                 From Homomorphic Encryption to Private AI: Successes, Challenges, and Opportunities -->
    <!--                             </a> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs8"> -->
    <!--                                 In this talk the audience will learn about modern homomorphic encryption and how it -->
    <!--                                 can be used to bring strong privacy guarantees to specific machine learning -->
    <!--                                 applications. We will also discuss limitations of homomorphic encryption in general, -->
    <!--                                 and specifically in the context of private machine learning, and get a glimpse of -->
    <!--                                 how some new exciting research directions may help resolve these challenges in the -->
    <!--                                 future. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Contributed slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">16:30</td> -->
    <!--                         <td class="slot talk"><a href="#tabs9" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 Efficient Secure Ridge Regression from Randomized Gaussian Elimination -->
    <!--                             </a> -->
    <!--                             (contributed talk) -->
    <!--                             &nbsp;&nbsp; -->
    <!--                             <br /> -->
    <!--                             <span style="font-weight: normal"> -->
    <!--                                 Frank Blom, Niek J. Bouman, Berry Schoenmakers and Niels de Vreede -->
    <!--                             </span> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs9"> -->
    <!--                                 In this paper we present a practical protocol for secure ridge regression. We -->
    <!--                                 develop the necessary secure linear algebra tools, using only basic arithmetic over -->
    <!--                                 prime fields. In particular, we will show how to solve linear systems of equations -->
    <!--                                 and compute matrix inverses efficiently, using appropriate secure random -->
    <!--                                 self-reductions of these problems. The distinguishing feature of our approach is -->
    <!--                                 that the use of secure fixed-point arithmetic is avoided entirely, while -->
    <!--                                 circumventing the need for rational reconstruction at any stage as well. We -->
    <!--                                 demonstrate the potential of our protocol in a standard setting for -->
    <!--                                 information-theoretically secure multiparty computation, tolerating a dishonest -->
    <!--                                 minority of passively corrupt parties. Using the MPyC framework, which is based on -->
    <!--                                 threshold secret sharing over finite fields, we show how to handle large datasets -->
    <!--                                 efficiently, achieving practically the same root-mean-square errors as Scikit-learn. -->
    <!--                                 Moreover, we do not assume that any (part) of the datasets is held privately by any -->
    <!--                                 of the parties, which makes our protocol much more versatile than existing -->
    <!--                                 solutions. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Contributed slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">16:50</td> -->
    <!--                         <td class="slot talk"><a href="#tabs10" data-toggle="collapse" class="accordion-toggle"> -->
    <!--                                 A verification framework for secure machine learning -->
    <!--                             </a> -->
    <!--                             (contributed talk) -->
    <!--                             &nbsp;&nbsp; -->
    <!--                             <br /> -->
    <!--                             <span style="font-weight: normal"> -->
    <!--                                 Prasad Naldurg and Karthikeyan Bhargavan -->
    <!--                             </span> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <tr> -->
    <!--                         <td colspan="2" class="hiddenRow"> -->
    <!--                             <div class="accordion-body collapse talk-abstract" id="tabs10"> -->
    <!--                                 We propose a programming and verification framework to help developers build -->
    <!--                                 distributed software applications using composite homomorphic encryption (and secure -->
    <!--                                 multi-party computation protocols), to implement secure machine learning and -->
    <!--                                 classification over private data. With our framework, a developer can prove that the -->
    <!--                                 application code is functionally correct, that it correctly composes the various -->
    <!--                                 cryptographic schemes it uses, and that it does not accidentally leak any secrets -->
    <!--                                 (via side-channels, for example.) Our end-to-end solution results in verified and -->
    <!--                                 efficient implementations of state-of-the-art secure privacy-preserving learning and -->
    <!--                                 classification techniques. -->
    <!--                             </div> -->
    <!--                         </td> -->
    <!--                     </tr> -->
    <!--                     <\!-- Basic slot -\-> -->
    <!--                     <tr> -->
    <!--                         <td class="time">17:10</td> -->
    <!--                         <td class="slot">Wrap-up</td> -->
    <!--                     </tr> -->
    <!--                 </tbody> -->
    <!--             </table> -->
    <!--         </div> -->
    <!--     </div> -->
    <!-- </section> -->
    <!-- <\!-- Accepted Papers -\-> -->

    <!-- <section id="papers" class="container content-section text-center"> -->
    <!--     <div class="row"> -->
    <!--         <div class="col-lg-8 col-lg-offset-2"> -->
    <!--             <h2>Accepted Papers</h2> -->
    <!--             <\!--<h4 style="color: #d07200;"> -->
    <!--             Links to pdfs as well as abstracts will be added soon. -->
    <!--             </h4>-\-> -->
    <!--             <div class="panel panel-default panel-paper"> -->
    <!--                 <div class="panel-body panel-paper-body"> -->
    <!--                     <span class="paper-author"> -->
    <!--                         Marshall Ball, Brent Carmer, Tal Malkin, Mike Rosulek and Nichole Schimanski. -->
    <!--                     </span> -->
    <!--                     <br /> -->
    <!--                     <a data-toggle="collapse" href="#abs0" class="paper-title"> -->
    <!--                         Garbled Neural Networks are Practical -->
    <!--                     </a> &nbsp;&nbsp; -->
    <!--                 </div> -->
    <!--                 <div id="abs0" class="panel-footer panel-paper-footer collapse"> -->
    <!--                     We show that garbled circuits offer a practical choice for secure evaluation of neural network -->
    <!--                     classifiers, comparable with complex, specialized protocols using less robust assumptions, many -->
    <!--                     rounds of interaction, and/or tailor-made neural networks. In particular, we develop a scheme -->
    <!--                     for garbling ``off the shelf'' pre-trained neural networks, where the only model preprocessing -->
    <!--                     required is a mild discretization step as opposed to requiring a specialized SFE-friendly model -->
    <!--                     to be independently trained. Moreover, as our solution is a garbling scheme, it inherits a much -->
    <!--                     more diverse range of applications than non-garbling-based solutions, perhaps most notably, -->
    <!--                     efficient compilers for the malicious setting. At the protocol level, we start with the garbling -->
    <!--                     scheme of Ball, Malkin, and Rosulek (ACM CCS 2016) for arithmetic circuits and introduce new -->
    <!--                     optimizations for modern neural network activation functions. We develop fancygarbling, the -->
    <!--                     first implementation of the BMR16 garbling scheme along with our new optimizations, as part of -->
    <!--                     heavily optimized garbled-circuits tool that is driven by a TensorFlow classifier description. -->
    <!--                     We evaluate our constructions on a wide range of neural networks. We find that our approach is -->
    <!--                     up to 100x more efficient than straight-forward boolean garbling. It is also roughly 40% more -->
    <!--                     efficient than DeepSecure (Rouhani et al., DAC 2018), a recent garbled-circuit-based approach -->
    <!--                     for secure neural network evaluation, which incorporates significant optimization techniques for -->
    <!--                     boolean circuits. Furthermore, our approach provides competitive performance tradeoffs -->
    <!--                     (efficiency and latency vs. communication) also when compared with non-garbled-circuit -->
    <!--                     approaches. -->
    <!--                 </div> -->
    <!--             </div> -->
    <!--             <div class="panel panel-default panel-paper"> -->
    <!--                 <div class="panel-body panel-paper-body"> -->
    <!--                     <span class="paper-author"> -->
    <!--                         Frank Blom, Niek J. Bouman, Berry Schoenmakers and Niels de Vreede. -->
    <!--                     </span> -->
    <!--                     <br /> -->
    <!--                     <a data-toggle="collapse" href="#abs1" class="paper-title"> -->
    <!--                         Efficient Secure Ridge Regression from Randomized Gaussian Elimination -->
    <!--                     </a> &nbsp;&nbsp; -->
    <!--                 </div> -->
    <!--                 <div id="abs1" class="panel-footer panel-paper-footer collapse"> -->
    <!--                     In this paper we present a practical protocol for secure ridge regression. We develop the -->
    <!--                     necessary secure linear algebra tools, using only basic arithmetic over prime fields. In -->
    <!--                     particular, we will show how to solve linear systems of equations and compute matrix inverses -->
    <!--                     efficiently, using appropriate secure random self-reductions of these problems. The -->
    <!--                     distinguishing feature of our approach is that the use of secure fixed-point arithmetic is -->
    <!--                     avoided entirely, while circumventing the need for rational reconstruction at any stage as well. -->
    <!--                     We demonstrate the potential of our protocol in a standard setting for information-theoretically -->
    <!--                     secure multiparty computation, tolerating a dishonest minority of passively corrupt parties. -->
    <!--                     Using the MPyC framework, which is based on threshold secret sharing over finite fields, we show -->
    <!--                     how to handle large datasets efficiently, achieving practically the same root-mean-square errors -->
    <!--                     as Scikit-learn. Moreover, we do not assume that any (part) of the datasets is held privately by -->
    <!--                     any of the parties, which makes our protocol much more versatile than existing solutions. -->
    <!--                 </div> -->
    <!--             </div> -->
                
    <!--             <\!--<div class="panel panel-default panel-paper"> -->
    <!--                 <div class="panel-body panel-paper-body"> -->
    <!--                     <span class="paper-author"> -->
    <!--                         AUTHOTS -->
    <!--                     </span> -->
    <!--                     <br /> -->
    <!--                     <a data-toggle="collapse" href="#abs8" class="paper-title"> -->
    <!--                         TITLE (paper with PDF) -->
    <!--                     </a> &nbsp;&nbsp; -->
    <!--                     <a href="papers/13.pdf" class="link-paper">[PDF]</a> -->
    <!--                 </div> -->
    <!--                 <div id="abs8" class="panel-footer panel-paper-footer collapse"> -->
    <!--                 ABSTRACT -->
    <!--                 </div> -->
    <!--             </div> -->

    <!--             <div class="panel panel-default panel-paper"> -->
    <!--                 <div class="panel-body panel-paper-body"> -->
    <!--                     <span class="paper-author"> -->
    <!--                     AUTHORS -->
    <!--                     </span> -->
    <!--                     <br /> -->
    <!--                     <a data-toggle="collapse" href="#abs1" class="paper-title"> -->
    <!--                     TITLE (paper with Arvix link) -->
    <!--                     </a> &nbsp;&nbsp; -->
    <!--                     <a href="https://arxiv.org/abs/1811.11124" class="link-paper">[arxiv]</a> -->
    <!--                 </div> -->
    <!--                 <div id="abs1" class="panel-footer panel-paper-footer collapse"> -->
    <!--                 ABSTRACT -->
    <!--                 </div> -->
    <!--             </div> -->

    <!--             <div class="panel panel-default panel-paper"> -->
    <!--                 <div class="panel-body panel-paper-body"> -->
    <!--                     <span class="paper-author"> -->
    <!--                         AUTHORS -->
    <!--                     </span> -->
    <!--                     <br /> -->
    <!--                     <a data-toggle="collapse" href="#abs11" class="paper-title"> -->
    <!--                         TITLE (paper with contributed talk) <font color="#d07200"><b>(contributed talk)</b></font> -->
    <!--                     </a> &nbsp;&nbsp; -->
    <!--                     <a href="https://arxiv.org/abs/1806.03287" class="link-paper">[arxiv]</a> -->
    <!--                 </div> -->
    <!--                 <div id="abs11" class="panel-footer panel-paper-footer collapse"> -->
    <!--                 ABSTRACT -->
    <!--                 </div> -->
    <!--             </div>-\-> -->
    <!--         </div> -->
    <!--     </div> -->

    <!-- </section> -->
    <!-- Organizers Section -->
    <section id="organizers" class="content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Organization</h2>
                <br />
                <h3>Workshop organizers</h3>
                <ul class="list-group">
                    <li class="list-group-item organizer">Borja Balle (DeepMind)</li>
                    <li class="list-group-item organizer">James Bell (The Alan Turing Institute)</li>
                    <li class="list-group-item organizer">Aurélien Bellet (Inria)</li>
                    <li class="list-group-item organizer">Kamalika Chaudhuri (University of California, San Diego)</li>
                    <li class="list-group-item organizer">Adria Gascon (Google)</li>
                    <li class="list-group-item organizer">Antti Honkela (University of Helsinki)</li>
                    <li class="list-group-item organizer">Antti Koskela (University of Helsinki)</li>
                    <li class="list-group-item organizer">Casey Meehan (University of California, San Diego)</li>
                    <li class="list-group-item organizer">Olya Ohrimenko (University of Melbourne)</li>
                    <li class="list-group-item organizer">Mijung Park (MPI Tuebingen)</li>
                    <li class="list-group-item organizer">Mariana Raykova (Google)</li>
                    <li class="list-group-item organizer">Mary Anne Smart (University of California, San Diego)</li>
                    <li class="list-group-item organizer">Yu-Xiang Wang (University of California, Santa Barbara)</li>
                    <li class="list-group-item organizer">Adrian Weller (Alan Turing Institute & Cambridge)</li>
                </ul>
                <br />
                <h3>Program Committee</h3>
                <ul class="list-group">
                    <!-- <li class="list-group-item organizer">Pauline Anthonysamy (Google)</li> -->
                    <!-- <li class="list-group-item organizer">Brendan Avent (USC)</li> -->
                    <!-- <li class="list-group-item organizer">Carsten Baum (BIU)</li> -->
                    <!-- <li class="list-group-item organizer">Aurélien Bellet (Inria)</li> -->
                    <!-- <li class="list-group-item organizer">Elette Boyle (IDC Herzliya)</li> -->
                    <!-- <li class="list-group-item organizer">Kamalika Chaudhuri (UCSD)</li> -->
                    <!-- <li class="list-group-item organizer">Giovanni Cherubin (EPFL)</li> -->
                    <!-- <li class="list-group-item organizer">Graham Cormode (University of Warwick)</li> -->
                    <!-- <li class="list-group-item organizer">Morten Dahl (Dropout Labs)</li> -->
                    <!-- <li class="list-group-item organizer">Christos Dimitrakakis (Chalmers University of Technology)</li> -->
                    <!-- <li class="list-group-item organizer">Jack Doerner (Northeastern)</li> -->
                    <!-- <li class="list-group-item organizer">Jamie Hayes (UCL)</li> -->
                    <!-- <li class="list-group-item organizer">Dali Kaafar (Macquarie University and Data61-CSIRO)</li> -->
                    <!-- <li class="list-group-item organizer">Peter Kairouz (Google)</li> -->
                    <!-- <li class="list-group-item organizer">Shiva Kasiviswanathan (Amazon)</li> -->
                    <!-- <li class="list-group-item organizer">Marcel Keller (Data61)</li> -->
                    <!-- <li class="list-group-item organizer">Niki Kilbertus (Cambridge University)</li> -->
                    <!-- <li class="list-group-item organizer">Ágnes Kiss (TU Darmstadt)</li> -->
                    <!-- <li class="list-group-item organizer">Nadin Kokciyan (King's College London)</li> -->
                    <!-- <li class="list-group-item organizer">Boris Köpf (Microsoft Research)</li> -->
                    <!-- <li class="list-group-item organizer">Aleksandra Korolova (USC)</li> -->
                    <!-- <li class="list-group-item organizer">Eleftheria Makri (KU Leuven)</li> -->
                    <!-- <li class="list-group-item organizer">Sebastian Meiser (Visa)</li> -->
                    <!-- <li class="list-group-item organizer">Luca Melis (Amazon)</li> -->
                    <!-- <li class="list-group-item organizer">Kartik Nayak (Duke University)</li> -->
                    <!-- <li class="list-group-item organizer">Catuscia Palamidessi (École Polytechnique & INRIA)</li> -->
                    <!-- <li class="list-group-item organizer">Peter Rindal (Visa Research)</li> -->
                    <!-- <li class="list-group-item organizer">Benjamin Rubinstein (University of Melbourne)</li> -->
                    <!-- <li class="list-group-item organizer">Anand Sarwate (Rutgers University)</li> -->
                    <!-- <li class="list-group-item organizer">Thomas Schneider (TU Darmstadt)</li> -->
                    <!-- <li class="list-group-item organizer">Peter Scholl (Aarhus University)</li> -->
                    <!-- <li class="list-group-item organizer">Or Sheffet (University of Alberta)</li> -->
                    <!-- <li class="list-group-item organizer">Nigel Smart (KU Leuven)</li> -->
                    <!-- <li class="list-group-item organizer">Adam Smith (Boston University)</li> -->
                    <!-- <li class="list-group-item organizer">Florian Tramer (Stanford)</li> -->
                    <!-- <li class="list-group-item organizer">Muthuramakrishnan Venkitasubramaniam (Rochester)</li> -->
                    <!-- <li class="list-group-item organizer">Xiao Wang (Northwestern University)</li> -->
                    <!-- <li class="list-group-item organizer">Kevin Yeo (Google)</li> -->
                    <!-- <li class="list-group-item organizer">Pinar Yolum (Utrecht University)</li> -->
                    <!-- <li class="list-group-item organizer">Yang Zhang (CISPA Helmholtz Center)</li> -->
                </ul>
                <br />
                <h3>Sponsors</h3>
                <br />
                <img style="margin:50px;" height="80" src="img/ati-white.png">
                <!-- <img style="margin:50px;" height="80" src="img/dropoutlabs.png"> -->
                <!-- <img style="margin:50px;" height="80" src="img/amazon.png"> -->
                <img style="margin:50px;" height="80" src="img/google.png">
                <!-- <img style="margin:50px;"height="80" src="img/microsoft.png"> -->
            </div>
        </div>
    </section>
    <!-- Organizers Section -->
    <section id="previous" class="content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Previous Editions</h2>
                <br />
                <ul class="list-group">
                  <li class="list-group-item event"><a href="ppml18/index.html">PPML'18</a> @ NeurIPS</li>
                  <li class="list-group-item event"><a href="ppml19/index.html">PPML'19</a> @ CCS</li>
                </ul>
            </div>
        </div>
    </section>
    <!-- Footer -->
    <footer>
        <div class="container text-center">
            <p>Contact us: <a href="mailto:ppml2020@easychair.org">ppml2020@easychair.org</a></p>
            <br />
        </div>
    </footer>
    <!-- jQuery -->
    <script src="js/jquery.min.js"></script>
    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>
    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <!-- Theme JavaScript -->
    <script src="js/script.js"></script>
</body>

</html>
